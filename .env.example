# Hugging Face token for model access (optional)
HF_TOKEN=your_hf_token_here

# Model configuration
BASE_MODEL=meta-llama/Llama-3.1-8B-Instruct
EMBEDDING_MODEL=intfloat/e5-large-v2
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Server configuration
API_HOST=0.0.0.0
API_PORT=8000
STREAMLIT_PORT=8501

# Data paths
RAW_PDFS_PATH=data/raw_pdfs
PROCESSED_DATA_PATH=data/processed
EVAL_DATA_PATH=data/eval

# Model output paths
SFT_OUTPUT_PATH=outputs/lora_sft
DPO_OUTPUT_PATH=outputs/lora_dpo

# Inference configuration
MAX_TOKENS=2048
TEMPERATURE=0.1
TOP_K=8
CHUNK_SIZE=1000
CHUNK_STRIDE=150